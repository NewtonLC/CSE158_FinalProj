{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import string\n",
    "import sklearn\n",
    "import statsmodels\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_recipes = pd.read_csv('RecipesDataset/RAW_recipes.csv', delimiter=\",\", low_memory=False)\n",
    "raw_interactions = pd.read_csv('RecipesDataset/RAW_interactions.csv', delimiter=\",\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out recipes with invalid minute times or take weeks of preparation\n",
    "filtered_recipes = raw_recipes[raw_recipes['minutes'] < 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out interactions that include recipes that were filtered out\n",
    "PP_interactions = raw_interactions[raw_interactions['recipe_id'].isin(filtered_recipes['id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GOAL:\n",
    "# Create a DataFrame off of interactions with the following columns:\n",
    "# user_id\n",
    "# recipe_id\n",
    "# rating\n",
    "# month - 1: January, 2: February, ..., 12: December\n",
    "# season - 0: winter, 1: spring, 2: summer, 3: fall\n",
    "# is_holiday_month - 1: yes, 0: no\n",
    "# pm_rating_avg - rating average of the recipe in the previous month\n",
    "# pm_review_count - number of reviews of the recipe in the previous month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GOAL:\n",
    "# Create a DataFrame off of recipes with the following columns:\n",
    "# recipe_id\n",
    "# minutes - time to prepare the recipe\n",
    "# rating_avg - (0-5)\n",
    "# review_count - number of reviews\n",
    "# has_seasonal_tag - 1: yes, 0: no\n",
    "# age - Time since the recipe was created to 2018-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['name', 'id', 'minutes', 'contributor_id', 'submitted', 'tags',\n",
      "       'nutrition', 'n_steps', 'steps', 'description', 'ingredients',\n",
      "       'n_ingredients'],\n",
      "      dtype='object')\n",
      "                                         name      id  minutes  \\\n",
      "0  arriba   baked winter squash mexican style  137739       55   \n",
      "1            a bit different  breakfast pizza   31490       30   \n",
      "2                   all in the kitchen  chili  112140      130   \n",
      "3                          alouette  potatoes   59389       45   \n",
      "4          amish  tomato ketchup  for canning   44061      190   \n",
      "\n",
      "   contributor_id   submitted  \\\n",
      "0           47892  2005-09-16   \n",
      "1           26278  2002-06-17   \n",
      "2          196586  2005-02-25   \n",
      "3           68585  2003-04-14   \n",
      "4           41706  2002-10-25   \n",
      "\n",
      "                                                tags  \\\n",
      "0  ['60-minutes-or-less', 'time-to-make', 'course...   \n",
      "1  ['30-minutes-or-less', 'time-to-make', 'course...   \n",
      "2  ['time-to-make', 'course', 'preparation', 'mai...   \n",
      "3  ['60-minutes-or-less', 'time-to-make', 'course...   \n",
      "4  ['weeknight', 'time-to-make', 'course', 'main-...   \n",
      "\n",
      "                                    nutrition  n_steps  \\\n",
      "0       [51.5, 0.0, 13.0, 0.0, 2.0, 0.0, 4.0]       11   \n",
      "1   [173.4, 18.0, 0.0, 17.0, 22.0, 35.0, 1.0]        9   \n",
      "2  [269.8, 22.0, 32.0, 48.0, 39.0, 27.0, 5.0]        6   \n",
      "3   [368.1, 17.0, 10.0, 2.0, 14.0, 8.0, 20.0]       11   \n",
      "4   [352.9, 1.0, 337.0, 23.0, 3.0, 0.0, 28.0]        5   \n",
      "\n",
      "                                               steps  \\\n",
      "0  ['make a choice and proceed with recipe', 'dep...   \n",
      "1  ['preheat oven to 425 degrees f', 'press dough...   \n",
      "2  ['brown ground beef in large pot', 'add choppe...   \n",
      "3  ['place potatoes in a large pot of lightly sal...   \n",
      "4  ['mix all ingredients& boil for 2 1 / 2 hours ...   \n",
      "\n",
      "                                         description  \\\n",
      "0  autumn is my favorite time of year to cook! th...   \n",
      "1  this recipe calls for the crust to be prebaked...   \n",
      "2  this modified version of 'mom's' chili was a h...   \n",
      "3  this is a super easy, great tasting, make ahea...   \n",
      "4  my dh's amish mother raised him on this recipe...   \n",
      "\n",
      "                                         ingredients  n_ingredients  \n",
      "0  ['winter squash', 'mexican seasoning', 'mixed ...              7  \n",
      "1  ['prepared pizza crust', 'sausage patty', 'egg...              6  \n",
      "2  ['ground beef', 'yellow onions', 'diced tomato...             13  \n",
      "3  ['spreadable cheese with garlic and herbs', 'n...             11  \n",
      "4  ['tomato juice', 'apple cider vinegar', 'sugar...              8  \n"
     ]
    }
   ],
   "source": [
    "print(raw_recipes.columns)\n",
    "print(raw_recipes.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'minutes', 'submitted', 'tags', 'age', 'has_seasonal_tag'], dtype='object')\n",
      "       id  minutes   submitted  \\\n",
      "0  137739       55  2005-09-16   \n",
      "1   31490       30  2002-06-17   \n",
      "2  112140      130  2005-02-25   \n",
      "3   59389       45  2003-04-14   \n",
      "4   44061      190  2002-10-25   \n",
      "\n",
      "                                                tags  age  has_seasonal_tag  \n",
      "0  ['60-minutes-or-less', 'time-to-make', 'course...   13                 0  \n",
      "1  ['30-minutes-or-less', 'time-to-make', 'course...   16                 0  \n",
      "2  ['time-to-make', 'course', 'preparation', 'mai...   13                 0  \n",
      "3  ['60-minutes-or-less', 'time-to-make', 'course...   15                 0  \n",
      "4  ['weeknight', 'time-to-make', 'course', 'main-...   16                 0  \n"
     ]
    }
   ],
   "source": [
    "# From the columns, id and minutes are already in the DataFrame\n",
    "# Let's add the age and has_seasonal_tag columns\n",
    "PP_recipes = filtered_recipes.drop(columns=['name', 'contributor_id', 'nutrition', 'n_steps', 'steps', 'description', 'ingredients', 'n_ingredients'])\n",
    "PP_recipes['age'] = 2018 - pd.to_datetime(PP_recipes['submitted']).dt.year\n",
    "\n",
    "seasonal_tags = ['holiday-event', 'seasonal', 'christmas', 'summer', 'fall', 'winter', 'spring', 'thanksgiving']\n",
    "\n",
    "PP_recipes['has_seasonal_tag'] = [1 if tag in seasonal_tags else 0 for tag in PP_recipes['tags']]\n",
    "\n",
    "print(PP_recipes.columns)\n",
    "print(PP_recipes.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add rating average and review count\n",
    "# Create a dictionary of recipe_id to a tuple of (rating_sum, review_count)\n",
    "# For each review in interactions, add the rating to the sum and increment the review count\n",
    "\n",
    "rating_dict = defaultdict(tuple)\n",
    "\n",
    "for index, row in PP_interactions.iterrows():\n",
    "    recipe_id = row['recipe_id']\n",
    "    rating = row['rating']\n",
    "    if recipe_id in rating_dict:\n",
    "        rating_dict[recipe_id] = (rating_dict[recipe_id][0] + rating, rating_dict[recipe_id][1] + 1)\n",
    "    else:\n",
    "        rating_dict[recipe_id] = (rating, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the rating average and review count to the DataFrame\n",
    "PP_recipes['rating_avg'] = [round(rating_dict[recipe_id][0] / rating_dict[recipe_id][1], 1) for recipe_id in PP_recipes['id']]\n",
    "PP_recipes['review_count'] = [rating_dict[recipe_id][1] for recipe_id in PP_recipes['id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'minutes', 'age', 'has_seasonal_tag', 'rating_avg',\n",
      "       'review_count'],\n",
      "      dtype='object')\n",
      "       id  minutes  age  has_seasonal_tag  rating_avg  review_count\n",
      "0  137739       55   13                 0         5.0             3\n",
      "1   31490       30   16                 0         3.5             4\n",
      "2  112140      130   13                 0         4.0             1\n",
      "3   59389       45   15                 0         4.5             2\n",
      "4   44061      190   16                 0         5.0             1\n"
     ]
    }
   ],
   "source": [
    "# Drop the submitted and tags columns.\n",
    "if 'submitted' in PP_recipes.columns and 'tags' in PP_recipes.columns:\n",
    "    PP_recipes = PP_recipes.drop(columns=['submitted', 'tags'])\n",
    "\n",
    "print(PP_recipes.columns)\n",
    "print(PP_recipes.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['user_id', 'recipe_id', 'date', 'rating', 'review'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Now let's do interactions.\n",
    "# GOAL:\n",
    "# Create a DataFrame off of interactions with the following columns:\n",
    "# user_id\n",
    "# recipe_id\n",
    "# rating\n",
    "# month - 1: January, 2: February, ..., 12: December\n",
    "# season - 0: winter, 1: spring, 2: summer, 3: fall\n",
    "# is_holiday_month - 1: yes, 0: no\n",
    "print(PP_interactions.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['user_id', 'recipe_id', 'date', 'rating'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Drop the review column\n",
    "if 'review' in PP_interactions.columns:\n",
    "    PP_interactions = PP_interactions.drop(columns=['review'])\n",
    "print(PP_interactions.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['user_id', 'recipe_id', 'date', 'rating', 'month', 'season',\n",
      "       'is_holiday_month'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Create month, season, is_holiday_month columns off of date\n",
    "PP_interactions['date'] = pd.to_datetime(PP_interactions['date'])\n",
    "PP_interactions['month'] = PP_interactions['date'].dt.month\n",
    "PP_interactions['season'] = [0 if month in [12, 1, 2] else 1 if month in [3, 4, 5] else 2 if month in [6, 7, 8] else 3 for month in PP_interactions['month']]\n",
    "PP_interactions['is_holiday_month'] = [1 if month in [11, 12, 1] else 0 for month in PP_interactions['month']]\n",
    "\n",
    "print(PP_interactions.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  recipe_id       date  rating  month  season  is_holiday_month\n",
      "0    38094      40893 2003-02-17       4      2       0                 0\n",
      "1  1293707      40893 2011-12-21       5     12       0                 1\n",
      "2     8937      44394 2002-12-01       4     12       0                 1\n",
      "3   126440      85009 2010-02-27       5      2       0                 0\n",
      "4    57222      85009 2011-10-01       5     10       3                 0\n",
      "       id  minutes  age  has_seasonal_tag  rating_avg  review_count\n",
      "0  137739       55   13                 0         5.0             3\n",
      "1   31490       30   16                 0         3.5             4\n",
      "2  112140      130   13                 0         4.0             1\n",
      "3   59389       45   15                 0         4.5             2\n",
      "4   44061      190   16                 0         5.0             1\n"
     ]
    }
   ],
   "source": [
    "print(PP_interactions.head())\n",
    "print(PP_recipes.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrames that filter out all recipes with under 5 interactions\n",
    "PP_recipes_5Rev = PP_recipes[PP_recipes['review_count'] >= 5]\n",
    "PP_interactions_5Rev = PP_interactions[PP_interactions['recipe_id'].isin(PP_recipes_5Rev['id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    user_id  recipe_id       date  rating  month  season  is_holiday_month\n",
      "8     76535     134728 2005-09-02       4      9       3                 0\n",
      "9    273745     134728 2005-12-22       5     12       0                 1\n",
      "10   353911     134728 2006-09-26       5      9       3                 0\n",
      "11   190375     134728 2007-03-09       5      3       1                 0\n",
      "12   468945     134728 2008-02-20       0      2       0                 0\n",
      "       id  minutes  age  has_seasonal_tag  rating_avg  review_count\n",
      "9   75452       70   15                 0         4.4             5\n",
      "15  63986      500   15                 0         4.4            19\n",
      "16  43026       45   16                 0         4.0            22\n",
      "17  23933       15   16                 0         4.8            12\n",
      "33  54100       26   15                 0         4.4            14\n",
      "1121540 803903\n",
      "229396 53150\n"
     ]
    }
   ],
   "source": [
    "print(PP_interactions_5Rev.head())\n",
    "print(PP_recipes_5Rev.head())\n",
    "\n",
    "print(len(PP_interactions), len(PP_interactions_5Rev))\n",
    "print(len(PP_recipes), len(PP_recipes_5Rev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = raw_interactions[raw_interactions['recipe_id'].isin(filtered_recipes['id'])]\n",
    "new_data = new_data[new_data['recipe_id'].isin(PP_recipes_5Rev['id'])]\n",
    "new_data['date'] = pd.to_datetime(new_data['date'])\n",
    "new_data = new_data.sort_values(by='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_train = new_data[new_data['date'].dt.year < 2013]\n",
    "new_data_valid = new_data[(new_data['date'].dt.year >= 2013) & (new_data['date'].dt.year <= 2015)]\n",
    "new_data_test = new_data[new_data['date'].dt.year > 2015]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor l in range(100, 101):\\n    model = AutoReg(new_data_train['rating'], lags=l)\\n    model_fit = model.fit()\\n\\n    valid_predictions = model_fit.predict(start=len(new_data_train), end=len(new_data_train) + len(new_data_valid) - 1, dynamic=False)\\n\\n    valid_ratings = new_data_valid['rating'].values\\n    valid_predictions = valid_predictions[:len(valid_ratings)]\\n\\n    valid_mse = mean_squared_error(new_data_valid['rating'], valid_predictions)\\n    valid_MSEs.append((valid_mse, l))\\n\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_MSEs = []\n",
    "\"\"\"\n",
    "for l in range(100, 101):\n",
    "    model = AutoReg(new_data_train['rating'], lags=l)\n",
    "    model_fit = model.fit()\n",
    "\n",
    "    valid_predictions = model_fit.predict(start=len(new_data_train), end=len(new_data_train) + len(new_data_valid) - 1, dynamic=False)\n",
    "\n",
    "    valid_ratings = new_data_valid['rating'].values\n",
    "    valid_predictions = valid_predictions[:len(valid_ratings)]\n",
    "\n",
    "    valid_mse = mean_squared_error(new_data_valid['rating'], valid_predictions)\n",
    "    valid_MSEs.append((valid_mse, l))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# (2.8264165802308145, 1)\n",
    "# (2.8264120072829284, 40)\n",
    "# (2.826362389377399, 60)\n",
    "# (2.8262528827609636, 100)\n",
    "print(valid_MSEs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "valid_ratings = new_data_valid['rating'].values\n",
    "valid_predictions = valid_predictions[:len(valid_ratings)]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE: 2.8264165802308145\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "valid_mse = mean_squared_error(new_data_valid['rating'], valid_predictions)\n",
    "print(f'Validation MSE: {valid_mse}')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aweso\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\aweso\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\aweso\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\statsmodels\\tsa\\deterministic.py:308: UserWarning: Only PeriodIndexes, DatetimeIndexes with a frequency set, RangesIndexes, and Index with a unit increment support extending. The index is set will contain the position relative to the data length.\n",
      "  fcast_index = self._extend_index(index, steps, forecast_index)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 5.07475858639176\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "test_predictions = model_fit.predict(start=len(new_data_train) + len(new_data_valid), end=len(new_data_train) + len(new_data_valid) + len(new_data_test) - 1, dynamic=False)\n",
    "\n",
    "test_ratings = new_data_test['rating'].values\n",
    "test_predictions = test_predictions[:len(test_ratings)]\n",
    "\n",
    "test_mse = mean_squared_error(test_ratings, test_predictions)\n",
    "print(f'Test MSE: {test_mse}')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of ['date'] are in the columns\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28028\\993244136.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mPP_interactions_5Rev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPP_interactions_5Rev\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mPP_interactions_5Rev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPP_interactions_5Rev\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\aweso\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[0;32m   6118\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfound\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6119\u001b[0m                         \u001b[0mmissing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6122\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"None of {missing} are in the columns\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6124\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6125\u001b[0m             \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of ['date'] are in the columns\""
     ]
    }
   ],
   "source": [
    "PP_interactions_5Rev = PP_interactions_5Rev.set_index('date')\n",
    "PP_interactions_5Rev = PP_interactions_5Rev.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            user_id  recipe_id  rating  month  season  is_holiday_month\n",
      "date                                                                   \n",
      "2000-01-25     2008       3603       4      1       0                 1\n",
      "2000-01-25     2008        992       5      1       0                 1\n",
      "2000-02-25     2046        517       5      2       0                 0\n",
      "2000-02-25     2046       4684       5      2       0                 0\n",
      "2000-02-25     2046       4523       2      2       0                 0\n",
      "DatetimeIndex(['2000-01-25', '2000-01-25', '2000-02-25', '2000-02-25',\n",
      "               '2000-02-25', '2000-03-13', '2000-03-13', '2000-04-07',\n",
      "               '2000-05-21', '2000-09-05',\n",
      "               ...\n",
      "               '2018-12-19', '2018-12-19', '2018-12-19', '2018-12-19',\n",
      "               '2018-12-19', '2018-12-19', '2018-12-19', '2018-12-19',\n",
      "               '2018-12-19', '2018-12-20'],\n",
      "              dtype='datetime64[ns]', name='date', length=803903, freq=None)\n"
     ]
    }
   ],
   "source": [
    "print(PP_interactions_5Rev.head())\n",
    "print(PP_interactions_5Rev.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "676445 73521 53937\n"
     ]
    }
   ],
   "source": [
    "# Set dataTest to the most recent data, from 2016-2018.\n",
    "# Set dataValid to the second most recent data, from 2013-2015.\n",
    "# Leave the remainder for dataTrain.\n",
    "dataTrain = PP_interactions_5Rev[PP_interactions_5Rev.index.year < 2013]\n",
    "dataValid = PP_interactions_5Rev[(PP_interactions_5Rev.index.year >= 2013) & (PP_interactions_5Rev.index.year <= 2015)]\n",
    "dataTest = PP_interactions_5Rev[(PP_interactions_5Rev.index.year > 2015)]\n",
    "print(len(dataTrain), len(dataValid), len(dataTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aweso\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    }
   ],
   "source": [
    "exog_features = ['season', 'is_holiday_month']\n",
    "model = AutoReg(dataTrain['rating'], lags=100, exog=dataTrain[exog_features])\n",
    "model_fit = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               user_id  recipe_id  rating  month  season  is_holiday_month\n",
      "date                                                                      \n",
      "2016-01-01  2000697576     150863       5      1       0                 1\n",
      "2016-01-01     1360126     297251       0      1       0                 1\n",
      "2016-01-01  2000791565      10744       0      1       0                 1\n",
      "2016-01-01  2000622331       2886       5      1       0                 1\n",
      "2016-01-01      223656      87881       5      1       0                 1\n"
     ]
    }
   ],
   "source": [
    "print(dataTest.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aweso\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\aweso\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\aweso\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\statsmodels\\tsa\\deterministic.py:308: UserWarning: Only PeriodIndexes, DatetimeIndexes with a frequency set, RangesIndexes, and Index with a unit increment support extending. The index is set will contain the position relative to the data length.\n",
      "  fcast_index = self._extend_index(index, steps, forecast_index)\n"
     ]
    }
   ],
   "source": [
    "valid_predictions = model_fit.predict(start=len(dataTrain), end=len(dataTrain)+len(dataValid)-1, exog_oos=dataValid[exog_features], dynamic=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ratings = dataValid['rating'].values\n",
    "valid_predictions = valid_predictions[:len(valid_ratings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE: 2.826118619758396\n",
      "Validation MSE: 2.826118619758396\n"
     ]
    }
   ],
   "source": [
    "#                 2.8264165802308145\n",
    "# Validation MSE: 2.826118619758396, lags=100\n",
    "valid_mse = mean_squared_error(valid_ratings, valid_predictions)\n",
    "print(f'Validation MSE: {valid_mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "749966 803902\n",
      "53936\n"
     ]
    }
   ],
   "source": [
    "start = len(dataTrain)+len(dataValid)\n",
    "end = len(dataTrain)+len(dataValid)+len(dataTest)-1\n",
    "\n",
    "print(start, end)\n",
    "print(end-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aweso\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\aweso\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\aweso\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\statsmodels\\tsa\\deterministic.py:308: UserWarning: Only PeriodIndexes, DatetimeIndexes with a frequency set, RangesIndexes, and Index with a unit increment support extending. The index is set will contain the position relative to the data length.\n",
      "  fcast_index = self._extend_index(index, steps, forecast_index)\n"
     ]
    }
   ],
   "source": [
    "test_predictions = model_fit.predict(start=len(dataTrain)+len(dataValid), end=len(dataTrain)+len(dataValid)+len(dataTest)-1, exog_oos=dataValid[exog_features]+dataTest[exog_features], dynamic=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratings = new_data_test['rating'].values\n",
    "test_predictions = test_predictions[:len(test_ratings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test_mse \u001b[38;5;241m=\u001b[39m \u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_ratings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_predictions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest MSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_mse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\aweso\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\aweso\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py:506\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m squared:\n\u001b[0;32m    502\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m root_mean_squared_error(\n\u001b[0;32m    503\u001b[0m             y_true, y_pred, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, multioutput\u001b[38;5;241m=\u001b[39mmultioutput\n\u001b[0;32m    504\u001b[0m         )\n\u001b[1;32m--> 506\u001b[0m y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    509\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    510\u001b[0m output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage((y_true \u001b[38;5;241m-\u001b[39m y_pred) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, weights\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[1;32mc:\\Users\\aweso\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py:113\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype, xp)\u001b[0m\n\u001b[0;32m    111\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m    112\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m--> 113\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    116\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mreshape(y_true, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\aweso\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:1064\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1059\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1060\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m   1061\u001b[0m     )\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m-> 1064\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1065\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1066\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1067\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1068\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[0;32m   1072\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[0;32m   1073\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aweso\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:123\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aweso\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:172\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    171\u001b[0m     )\n\u001b[1;32m--> 172\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN."
     ]
    }
   ],
   "source": [
    "test_mse = mean_squared_error(test_ratings, test_predictions)\n",
    "print(f'Test MSE: {test_mse}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
